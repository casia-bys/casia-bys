{
  "title": "EasyInsert: A Data-Efficient and Generalizable Insertion Policy",
  "authors": [
    "Guanghe Li",
    "Junming Zhao",
    "Shengjie Wang",
    "Yang Gao"
  ],
  "abstract": "Insertion task is highly challenging that requires robots to operate with exceptional precision in cluttered environments. Existing methods often have poor generalization capabilities. They typically function in restricted and structured environments, and frequently fail when the plug and socket are far apart, when the scene is densely cluttered, or when handling novel objects. They also rely on strong assumptions such as access to CAD models or a digital twin in simulation. To address this, we propose EasyInsert, a framework which leverages the human intuition that relative pose (delta pose) between plug and socket is sufficient for successful insertion, and employs efficient and automated real-world data collection with minimal human labor to train a generalizable model for relative pose prediction. During execution, EasyInsert follows a coarse-to-fine execution procedure based on predicted delta pose, and successfully performs various insertion tasks. EasyInsert demonstrates strong zero-shot generalization capability for unseen objects in cluttered environments, handling cases with significant initial pose deviations while maintaining high sample efficiency and requiring little human effort. In real-world experiments, with just 5 hours of training data, EasyInsert achieves over 90% success in zero-shot insertion for 13 out of 15 unseen novel objects, including challenging objects like Type-C cables, HDMI cables, and Ethernet cables. Furthermore, with only one human demonstration and 4 minutes of automatically collected data for fine-tuning, it reaches over 90% success rate for all 15 objects.",
  "published": "2025-05-22",
  "arxiv_id": "2505.16187",
  "url": "https://arxiv.org/abs/2505.16187",
  "analysis": {
    "基本信息": {
      "论文标题": "EasyInsert: A Data-Efficient and Generalizable Insertion Policy",
      "arXiv ID": "2505.16187",
      "作者": [
        "Guanghe Li",
        "Junming Zhao",
        "Shengjie Wang",
        "Yang Gao"
      ],
      "所属机构": "Tsinghua University; Shanghai AI Laboratory; Shanghai Qi Zhi Institute; Jilin University; Fudan University",
      "关键词": [
        "Robot Manipulation",
        "Generalizable Insertion",
        "Efficient Data Collection",
        "Delta-Pose Prediction",
        "Zero-shot Generalization"
      ]
    },
    "1_问题背景与动机": {
      "研究问题": "机器人插拔任务在复杂/杂乱环境、远距离初位姿态以及未见物体条件下，如何实现高精度、强泛化、低人工成本的学习与执行策略。",
      "现有挑战": [
        "挑战1：现有方法依赖CAD模型/数字孪生或仿真-现实迁移，易受仿真-现实域间差异影响。",
        "挑战2：对未见物体与多样化环境泛化差，难以在远距离初位、密集遮挡、杂乱场景中保持稳定。",
        "挑战3：数据收集成本高（人工示教或大量真实交互），模型易在近接触区做出分歧决策，学习目标不稳定。"
      ],
      "研究动机": "工厂装配、仓储拣选与电子装配等场景需要通用、鲁棒且低人工成本的插拔策略；仅5小时训练数据即可泛化到15种未见对象，支持零样本/少样本适配，满足现实部署效率与可扩展性要求。",
      "gap分析": "传统与部分学习式方法需严格定位插座（1–2 cm精度）或依赖干净工位；相对位姿（delta pose）估计的插拔方法可绕开动作分歧与近接触区学习不稳定问题，实现粗到细的人启发式执行。"
    },
    "2_方法核心思想": {
      "方法概述": "将插拔建模为视觉输入下的相对位姿（delta pose）预测问题，并采用粗到细执行策略（对齐→微调→近接触探索），结合半自动化数据采集与扩散策略学习，实现数据高效与跨对象/环境泛化。",
      "整体架构": "（1）混合数据采集：自动+人工（20%），覆盖5类插拔物对，合计5小时数据；（2）通用策略预训练：双腕摄像头RGB图像→ResNet18共享编码→扩散动作头预测4-DoF delta pose；（3）执行层：粗到细分层规划，基于预测delta pose更新目标位姿；（4）可选一键微调：单次示教+4分钟自动采集数据，仅调学习率等参数与预训练一致。",
      "核心创新点": [
        {
          "创新1": "以delta pose替代直接动作预测：标签可由抓取器位姿与插接到位姿直接计算，降低人工示教成本；相对位姿目标更平滑连续，缓解近接触区决策分歧问题。"
        },
        {
          "创新2": "半自动化数据采集与安全保护：在10–15 Hz频率同步采集双图像与位姿；自动随机采样位姿与高速运动规划；当抓取器高度低于安全阈值时触发2秒向上避障，确保无碰撞。"
        },
        {
          "创新3": "人启发的粗到细执行：当水平位移或偏航角超阈值δ（未给出具体值）时，先抬升至安全高度H=6 cm对齐上方，再进行细调与近接触微调；姿态更新按4-DoF独立叠加pg = (x,y,z,ψ)+Δp。"
        }
      ],
      "方法来源": "人类插拔的直觉：远距粗对齐→近距离细调→近接触微探索；期间持续估计插头与插座的相对位姿是关键。"
    },
    "3_具体方法表述（最重要）": {
      "模块A": {
        "名称": "混合数据采集模块",
        "作用": "构建通用预训练数据集与可选微调数据集，覆盖插座周围的大范围空间与近接触区域，同时引入环境杂乱扰动以提升泛化。",
        "输入": "工作区内随机或人工指定的抓取器位姿pi=(x,y,z,ψ)；双腕摄像头图像对Oi1,Oi2；安全高度检测信号。",
        "输出": "训练样本D = {(Oi1,Oi2,Δpi)}N，其中Δpi为插头相对插座的4-DoF位姿变换：(Δx,Δy,Δz,Δψ)。",
        "实现细节": "自动采集：通过随机位姿采样与高速运动规划在预定义工作区内移动抓取器；同步采集频率10–15 Hz；高度低于安全阈值时向上提升2秒避障。人工采集（20%）：在近接触区由操作员拖拽Franka记录细粒度交互；数据收集时人类引入环境变化（随机摆放干扰物）。",
        "关键代码/公式": "数据样本定义：D = {(Oi1, Oi2, Δpi)}N，其中Δpi ∈ R^4；位姿加法（4-DoF）：pg = (x,y,z,ψ) + (Δx,Δy,Δz,Δψ)。",
        "参数设置": "采集频率：10–15 Hz；自动/人工比例：约80%/20%；垂直安全高度H=6 cm；自动避障：低于阈值触发向上运动2秒。"
      },
      "模块B": {
        "名称": "通用策略预训练（视觉-相对位姿预测）",
        "作用": "从双RGB图像中学习预测插头与插座的相对位姿Δp，为后续粗到细执行提供目标位姿估计。",
        "输入": "双腕摄像头图像对Oi1,Oi2（RGB）；可选条件：时间步t（扩散噪声调度）。",
        "输出": "Δp=(Δx,Δy,Δz,Δψ) ∈ R^4；推理加速采用DDIM。",
        "实现细节": "编码器：ResNet18（ImageNet预训练）作为共享编码器；特征融合：将两路512-d特征拼接为f∈R^1024；扩散动作头：DDPM/DDIM，噪声估计器εθ对Δp进行去噪；强颜色增强（color jitter与随机灰度）提升域鲁棒性。",
        "关键代码/公式": "特征融合：f = concat([E(Oi1), E(Oi2)])；扩散目标：L_diff = E_t,ε[||ε - εθ(xt|t, f)||^2]；DDIM采样（推理加速）：xt-1 = α̅_t-1·( (xt - α_t·εθ(xt|t,f)) / α̅_t ) + σ_t·z，其中z为噪声。",
        "参数设置": "编码器：ResNet18；融合维度：1024-d；扩散噪声调度：T=100（论文采用DDPM训练，推理用DDIM加速）；推理步数：DDIM加速（未给出具体步数）。"
      },
      "模块C": {
        "名称": "粗到细执行策略",
        "作用": "基于Δp估计进行分层位姿规划与动作执行，兼顾安全对齐与近接触精度。",
        "输入": "当前抓取器位姿p=(x,y,z,ψ)；预测相对位姿Δp=(Δx,Δy,Δz,Δψ)；阈值δ（用于切换阶段，论文未给出数值）。",
        "输出": "下一目标位姿pnext及其路径执行；最终成功插接位姿pg = p + Δp。",
        "实现细节": "粗对齐阶段：若水平位移或偏航角超阈值δ，则先将抓取器抬升至安全高度H=6 cm的pnext=(gx, gy, gz+H, gψ)。细调阶段：接近目标后基于Δp进行小幅渐进调整。近接触：微探索直至成功。",
        "关键代码/公式": "位姿更新：pg = (x,y,z,ψ) + (Δx,Δy,Δz,Δψ)；粗对齐目标：pnext = (gx, gy, gz+H, gψ)，其中H=6 cm。",
        "参数设置": "H=6 cm；δ未指定（由系统实验经验设定）；执行由运动规划器分步移动至pnext。"
      },
      "模块D": {
        "名称": "一键微调（One-shot Adaptation）",
        "作用": "针对目标对象在仅一次示教与约4分钟自动采集数据下，对通用模型进行微调，使成功率覆盖全部15个未见对象。",
        "输入": "单次人工示教的位姿/交互样本；自动采集的约4分钟数据。",
        "输出": "更新后的Δp预测模型（保持与预训练相同的学习率等超参）。",
        "实现细节": "沿用预训练结构与训练配置；无需额外人工数据与环境变化；仅利用自动采集数据完成适配。",
        "关键代码/公式": "微调目标：最小化与预训练相同的扩散去噪损失L_diff；学习率与预训练阶段相同。",
        "参数设置": "微调数据量：约4分钟；人工示教：1次；学习率：与预训练相同。"
      }
    },
    "4_训练与损失函数": {
      "损失函数": [
        {
          "L1": "扩散去噪均方误差损失",
          "公式": "L_diff = E_{t, ε}[‖ε - ε_θ(x_t | t, f)‖_2^2]",
          "作用": "约束噪声估计器在给定观测特征与扩散时间步条件下，对加噪的delta pose进行去噪，间接学习Δp预测分布。"
        }
      ],
      "训练策略": "分两阶段：预训练（5小时混合数据，D={(Oi1,Oi2,Δpi)}）→ 扩散策略学习；推理采用DDIM加速；可选微调（单示教+4分钟自动采集）。",
      "优化器": "论文未给出具体优化器与参数（Adam/SGD等未详述）。",
      "学习率调度": "论文未给出学习率与调度策略；微调阶段学习率与预训练保持一致。"
    },
    "5_特征设计": {
      "特征类型1": "双腕摄像头RGB图像（Oi1, Oi2），单张典型分辨率为224×224×3（ResNet18标准输入）。",
      "特征类型2": "共享ResNet18编码特征，每张图像对应512-d特征向量；融合后为1024-d。",
      "融合方式": "特征拼接（concat）形成f∈R^1024，输入扩散动作头；必要时可采用通道注意或相加，但论文为拼接。",
      "维度变化": "RGB(224×224×3) → ResNet18 → 512-d → 拼接至1024-d → 扩散动作头(噪声估计器εθ) → 输出Δp∈R^4。"
    },
    "6_实验细节": {
      "数据集": "预训练：5小时混合数据，覆盖5类插拔对象；测试：15个未见对象（Type-C/HDMI/Ethernet等线缆与几何形状多样）。",
      "评估指标": "插拔成功率（%）；零样本与一键微调设置下分别统计。",
      "实现环境": "Franka Panda机械臂；双腕摄像头RGB输入；运动规划器执行路径。",
      "对比方法": "论文未详尽列出具体基线名称与结果；强调方法在零样本下对13/15对象达到>90%成功率；一键微调后对所有15对象>90%。"
    },
    "7_可借鉴句子": [
      "‘Inspired by this, we propose a novel method that formulates insertion as a delta-pose prediction problem instead of direct action prediction.’",
      "‘Collecting a delta-pose dataset is significantly easier. ... Delta-pose can be computed directly from the gripper’s pose at the insertion point and its current pose.’",
      "‘Delta-pose prediction provides a more stable learning objective, maintaining smooth continuity. In contrast, direct action prediction may require highly divergent decisions in close proximity regions.’"
    ],
    "8_专业术语": [
      {
        "术语": "Delta pose（相对位姿）",
        "中文": "相对位姿",
        "解释": "当前抓取器姿态到成功插接姿态的4-DoF变换（Δx, Δy, Δz, Δψ）。",
        "使用场景": "用于从视觉估计目标位姿，执行粗到细插接。"
      },
      {
        "术语": "Wrist-mounted cameras（腕部摄像头）",
        "中文": "腕部摄像头",
        "解释": "安装在机械臂末端执行器上的RGB摄像头，用于近场视觉观测。",
        "使用场景": "采集双视角图像，融合预测Δp。"
      },
      {
        "术语": "Diffusion Policy（扩散策略）",
        "中文": "扩散策略",
        "解释": "用扩散模型的动作分布建模动作/位姿预测，采用DDPM训练与DDIM推理加速。",
        "使用场景": "预测Δp，提升稳定性和鲁棒性。"
      }
    ],
    "9_图表分析": [
      {
        "图表": "图1：框架总览",
        "内容": "展示零样本泛化评估（对象与空间复杂度）、数据采集比例与对象覆盖、通用策略在多对象上的性能概览。",
        "设计亮点": "用水平/垂直两维展示对象与环境复杂度，清晰体现方法跨维度的泛化能力。",
        "可借鉴点": "在论文总览图中同时展示数据、对象覆盖与评估维度，提升整体说服力。"
      },
      {
        "图表": "图2：方法概览",
        "内容": "混合数据采集、通用策略训练与一键微调流程；人类启发的粗到细执行。",
        "设计亮点": "模块化呈现训练-执行-适配三阶段，强调自动化与低人工负担。",
        "可借鉴点": "将数据、策略、执行串为单一流程，便于工程复现。"
      },
      {
        "图表": "图3：粗到细执行流程",
        "内容": "对齐→细调→近接触三阶段示意图。",
        "设计亮点": "直观展示安全高度H与阶段切换逻辑，便于实现落地。",
        "可借鉴点": "在插拔等高精度任务中采用分层执行，增强稳定性与容错性。"
      }
    ],
    "10_论文总结": {
      "核心贡献": "提出以delta pose预测为核心的插拔框架，结合半自动数据采集与扩散策略，实现5小时数据预训练下的强零样本泛化；一键微调后覆盖全部15个未见对象。",
      "方法优势": "数据效率高（5小时），自动化程度高（80%自动+20%人工），执行稳健（粗到细），跨对象/环境泛化显著（>90%成功率），且对初位姿态偏差与杂乱环境有较强容忍。",
      "局限性": "假设插座水平与插头轴线对齐；4-DoF简化可能限制更复杂姿态插接；推理DDIM具体步数与超参未详述；对比基线与精确定量曲线未完整提供。",
      "应用场景": "工厂装配、电子产品插接、线缆整理、仓储拣选等需要高精度与通用性的接触丰富操作。"
    },
    "11_阅读建议": {
      "核心学习点": "以delta pose替代直接动作预测的思路；半自动数据采集与安全防护策略的工程实现。",
      "复现建议": "双ResNet18编码与1024-d拼接输入扩散动作头；DDPM训练+DDIM推理；采集频率10–15 Hz；安全阈值触发2秒向上避障；粗对齐H=6 cm；阈值δ由实验调参确定；强颜色增强（color jitter/随机灰度）。",
      "扩展方向": "扩展到无水平假设与更高DoF（加入roll/pitch）；探索更少示教（如零样本全自动化微调）；引入触觉/力控提升近接触精度；对比更全面的基线与曲线；针对不同杂乱度进行系统性消融。"
    }
  },
  "analyzed_at": "2026-01-22T00:22:25.735021"
}