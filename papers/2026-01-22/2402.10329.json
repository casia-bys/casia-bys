{
  "title": "Universal Manipulation Interface: In-The-Wild Robot Teaching Without In-The-Wild Robots",
  "authors": [
    "Cheng Chi",
    "Zhenjia Xu",
    "Chuer Pan",
    "Eric Cousineau",
    "Benjamin Burchfiel",
    "Siyuan Feng",
    "Russ Tedrake",
    "Shuran Song"
  ],
  "abstract": "We present Universal Manipulation Interface (UMI) -- a data collection and policy learning framework that allows direct skill transfer from in-the-wild human demonstrations to deployable robot policies. UMI employs hand-held grippers coupled with careful interface design to enable portable, low-cost, and information-rich data collection for challenging bimanual and dynamic manipulation demonstrations. To facilitate deployable policy learning, UMI incorporates a carefully designed policy interface with inference-time latency matching and a relative-trajectory action representation. The resulting learned policies are hardware-agnostic and deployable across multiple robot platforms. Equipped with these features, UMI framework unlocks new robot manipulation capabilities, allowing zero-shot generalizable dynamic, bimanual, precise, and long-horizon behaviors, by only changing the training data for each task. We demonstrate UMI's versatility and efficacy with comprehensive real-world experiments, where policies learned via UMI zero-shot generalize to novel environments and objects when trained on diverse human demonstrations. UMI's hardware and software system is open-sourced at https://umi-gripper.github.io.",
  "published": "2024-02-15",
  "arxiv_id": "2402.10329",
  "url": "https://arxiv.org/abs/2402.10329",
  "analysis": {
    "基本信息": {
      "论文标题": "Universal Manipulation Interface: In-The-Wild Robot Teaching Without In-The-Wild Robots",
      "arXiv ID": "2402.10329",
      "作者": [
        "Cheng Chi",
        "Zhenjia Xu",
        "Chuer Pan",
        "Eric Cousineau",
        "Benjamin Burchfiel",
        "Siyuan Feng",
        "Russ Tedrake",
        "Shuran Song"
      ],
      "所属机构": "Stanford University; Columbia University; Toyota Research Institute",
      "关键词": [
        "Universal Manipulation Interface",
        "handheld gripper",
        "visual-inertial SLAM",
        "latency matching",
        "diffusion policy",
        "relative trajectory"
      ]
    },
    "1_问题背景与动机": {
      "研究问题": "如何在不使用“在野机器人”的前提下，以低成本、便携方式收集动作多样、信息丰富的人类演示，并直接将其迁移为可部署的机器人策略。",
      "现有挑战": [
        "挑战1：视觉上下文不足。使用腕上单目相机会导致严重遮挡和场景覆盖不足，难以支撑动作规划。",
        "挑战2：动作精度不足。基于单目SfM的端部6DoF恢复存在尺度歧义、运动模糊、纹理缺失等问题，难以用于精细与动态任务。",
        "挑战3：时延不匹配。人类演示无感知/执行延迟，机器人推理/执行存在多层延迟，导致训练/推理观测-动作不同步。",
        "挑战4：策略表示不足。简单回归式策略难以拟合人类数据中的多模态动作分布。"
      ],
      "研究动机": "降低数据收集门槛、提升动作精度与泛化能力，实现硬件无关、可零样本迁移的动态/双手/精细/长时序操纵策略。",
      "gap分析": "传统手持设备受限于视觉覆盖与端部位姿精度，传统基于人类视频的方法存在本体鸿沟与动作缺失；UMI通过硬件与策略接口的协同设计弥补上述差距。"
    },
    "2_方法核心思想": {
      "方法概述": "UMI以手持并口夹爪+GoPro为唯一传感器，集成155°鱼眼镜头与侧镜形成隐式双目视觉，并利用GoPro内置IMU进行视觉-惯性联合SLAM以高保真恢复6DoF端部轨迹；在策略层面引入推理时延匹配与相对轨迹动作表示，并采用Diffusion Policy拟合多模态动作分布，实现硬件无关的跨平台部署。",
      "整体架构": "演示接口(鱼眼+侧镜+IMU+SLAM)→ 数据过滤(尺度/可达性/姿态平滑)→ 策略接口(相对轨迹+延迟匹配+Diffusion Policy)→ 多平台部署(无标定、相机相对手指固定)。",
      "核心创新点": [
        {
          "创新1": "隐式立体与宽视场视觉上下文：155°鱼眼镜头保持中心高分辨率、压缩边缘；两侧镜提供虚拟多视角反射，形成隐式双目信息；输入为原始鱼眼图像与数字反射的侧镜裁剪。"
        },
        {
          "创新2": "IMU感知的视觉惯性SLAM：基于ORB-SLAM3联合优化视觉特征与惯性约束，在快速运动/运动模糊下仍维持绝对尺度与短时鲁棒追踪，用于高保真6DoF端部位姿恢复。"
        },
        {
          "创新3": "策略接口的双重匹配：推理时延匹配(随机延迟/动作延迟缓冲)以缓解训练-推理不同步；相对轨迹动作表示以消除对精确绝对位姿的需求；策略采用Diffusion Policy对多模态动作分布建模。"
        }
      ],
      "方法来源": "手持夹爪数据收集的中间路线(介于机器人遥操与纯视频学习之间)；鱼眼与侧镜的宽上下文视觉方案；ORB-SLAM3为视觉惯性SLAM基线；动作多模态采用Diffusion Policy。"
    },
    "3_具体方法表述（最重要）": {
      "模块A": {
        "名称": "演示接口硬件与观察表征",
        "作用": "以手持夹爪+GoPro完成便携、低成本、信息丰富的演示采集；为策略输入提供一致的视觉观察空间并最小化本体鸿沟。",
        "输入": "GoPro单目原始鱼眼图像(含内置IMU加速度计/陀螺仪序列)、两侧镜区域裁剪(数字反射校正方向)、触发信号(夹爪开关)。",
        "输出": "去畸变前的鱼眼观测图(保持中心高分辨率)、镜像数字反射后的侧镜裁剪序列、IMU数据流(与视频帧对齐的时间戳)。",
        "实现细节": "1) 相机机械固定于夹爪指尖坐标系，保证人/机器人观察一致性，无需相机-机器人-世界外参标定；2) 155°鱼眼镜头提升场景覆盖与特征重叠；3) 侧镜在相机外围视野内形成隐式立体视图，使用数字反射以统一物体朝向；4) 侧裁剪坐标与镜像反射策略由镜像平面几何关系决定，确保主/左/右视图在语义上对齐。",
        "关键代码/公式": "镜像反射(概念表述)：设主相机坐标系C_m，镜像虚拟相机C_m'由镜像平面S反射得到，图像坐标u∈C_m'经数字反射变换R(u)投影回主图像坐标系，构成策略输入I' = I_m ⋃ R(I_{mirror})；物理实现细节以镜像平面与光轴的几何关系求解R。",
        "参数设置": "FOV=155°(鱼眼镜头规格)；侧镜位置按几何布局以覆盖夹爪关键可视区域(论文未给出绝对尺寸坐标)；GoPro内置IMU以标准mp4封装并与视频帧时间戳对齐。"
      },
      "模块B": {
        "名称": "视觉-惯性6DoF端部位姿恢复",
        "作用": "以绝对尺度恢复端部全局位姿，支持快速、动态操作下的稳定追踪。",
        "输入": "原始鱼眼图像序列I_t、IMU数据(加速度a_t、角速度ω_t)、侧镜裁剪序列(可选增强特征)、时间戳。",
        "输出": "相机-指尖坐标系C_f下的全局位姿序列{SE(3)}_t=(R_t, p_t)、端部速度与角速度、状态协方差。",
        "实现细节": "基于ORB-SLAM3进行视觉惯性SLAM：1) ORB特征提取与匹配(鱼眼/侧镜图像提高鲁棒性)；2) IMU预积分约束融入位姿图优化；3) 在短时视觉退化时依靠IMU维持跟踪与绝对尺度；4) 联立优化外参与尺度，使R_t, p_t在全局一致。",
        "关键代码/公式": "视觉惯性SLAM的预积分与残差(概念表述)：最小化 E = Σ ρ(|| r_c(z_{c_k}, ξ)||^2 + || r_IMU(z_{b_{k+1}}^b_k, ξ)||^2)，其中r_c为相机重投影残差，r_IMU为IMU预积分残差，ξ为状态变量(位姿、速度、偏置)。",
        "参数设置": "特征点数、阈值等由ORB-SLAM3默认参数与现场图像纹理决定；相机-指尖外参固定；IMU与视频以mp4封装方式时间对齐。"
      },
      "模块C": {
        "名称": "动作提取与数据过滤",
        "作用": "从6DoF位姿序列提取连续、绝对尺度一致、满足机器人运动学约束的动作；剔除不可达或不稳定轨迹。",
        "输入": "SE(3)_t序列、IMU/位姿协方差、机器人DH或URDF(6/7DoF臂+并口夹爪)、夹爪开闭事件。",
        "输出": "可达的端部轨迹序列{Δq_t}与夹爪开闭序列{Δg_t}；相对轨迹表示T_rel = {(Δp_{t→t+H}, ΔR_{t→t+H}, Δg_{t→t+H})}，H为预测时域。",
        "实现细节": "1) 位姿对齐与尺度校正：以指尖坐标系下全局位姿为基准，补偿镜头与指尖偏置；2) 姿态平滑与数值稳定：采用指数平滑或低通滤波避免高频抖动；3) 机器人运动学逆解：对6/7DoF臂使用数值/解析逆运动学生成关节增量Δq_t，剔除奇异或超界解；4) 尺度/速度阈值过滤：筛除位移幅度过大(如>30 cm)或角速度异常的轨迹段；5) 双手示范：双夹爪分别恢复位姿后做时间对齐与协调性筛选(论文强调可行但未给参数)。",
        "关键代码/公式": "相对轨迹(概念表述)：设t时刻绝对位姿为P_t=(R_t, p_t)，相对增量定义为 ΔP_{t→t+H} = P_{t+H} ∘ P_t^{-1}；对应平移Δp与旋转ΔR用李群SE(3)运算定义。",
        "参数设置": "滤波系数、低通截止频率、位移/角速度阈值按机器人与任务动态性设置(论文未给出具体数值)；预测时域H由策略输入窗口与任务horizon决定。"
      },
      "模块D": {
        "名称": "策略接口与时延匹配",
        "作用": "对齐训练/推理时延，消除快/动态动作的分布外输入，保证策略在真实系统上稳定执行。",
        "输入": "训练时注入的随机延迟τ∼U[τ_min, τ_max]、推理侧传感器/推理/执行延迟的测量值τ_sys、相对轨迹目标T_rel。",
        "输出": "延迟匹配后的观测-动作对(用于训练)与推理时执行的策略输出。",
        "实现细节": "1) 训练时：构造动作延迟缓冲(队列)，对目标相对轨迹τ步延迟后与当前观测对齐；2) 推理时：在策略输出与底层执行器之间加入与τ_sys等价的固定/自适应延迟缓冲；3) 动作延迟注入与同步控制：对连续动作按固定采样周期Δt执行，在多源延迟存在时通过时钟同步确保Δt对齐；4) 为缓解观测非平稳性，可使用历史观测堆栈或轻量时序编码(论文未详述)。",
        "关键代码/公式": "延迟同步(概念表述)：o_t为t时刻观测，a_t为策略输出，令 a_t = π(o_{t-τ})，其中τ为注入/系统延迟；执行端保证a_t在时间t+τ的应用时间戳与机器人控制周期Δt对齐。",
        "参数设置": "τ_min, τ_max由任务动态性与系统测量确定(论文未给具体区间)；Δt与机器人控制频率一致(如100–200Hz常见于末端执行)。"
      },
      "模块E": {
        "名称": "策略学习：Diffusion Policy(相对轨迹动作表示)",
        "作用": "对人类演示的多模态动作分布进行条件生成，输出稳定的相对轨迹控制命令。",
        "输入": "观测O(原始鱼眼图像+侧镜数字反射裁剪)、可选历史堆栈O_{t-K:t}；相对轨迹条件C=T_rel(多步增量)。",
        "输出": "多步相对轨迹预测(Δp, ΔR, Δg)的分布参数或直接样本。",
        "实现细节": "1) 条件扩散模型：基于DDPM/DDIM噪声调度对相对轨迹序列建模，噪声预测网络以观测为条件；2) 条件编码：对图像序列使用视觉编码器(卷积+时序Transformer/GRU等)得到条件嵌入z_O；3) 多模态拟合：通过逐步去噪覆盖抓取力度变化、路径选择等模态差异；4) 推理时采用多步采样与轨迹平滑；5) 部署硬件无关：策略输出相对增量+延迟缓冲，无需全局位姿与外参。",
        "关键代码/公式": "扩散损失(概念表述)：L = E_{t∼[1,T], ε∼N(0,I)} [ || ε - ε_θ(x_t, t, c) ||^2 ]，其中x_t为带噪相对轨迹，c为观测条件(图像+历史)，ε_θ为噪声预测网络。推理采样(示意)：x_{t-1} = μ_θ(x_t, t, c) + σ_t z；或DDIM确定性采样。",
        "参数设置": "扩散步数T(如50/100)、噪声调度(线性/余弦)、网络层数与通道数、时域窗口长度L(如10–50帧)、采样步数K(与执行周期匹配)等具体超参数未在摘要与前18页给出；实现参考“Diffusion Policy”开源配置。"
      },
      "模块F": {
        "名称": "部署与执行接口",
        "作用": "保证策略输出在不同机器人平台上的无缝映射与低延迟执行。",
        "输入": "策略输出的相对轨迹ΔP、夹爪开闭Δg、延迟缓冲器状态。",
        "输出": "关节增量命令Δq(由逆运动学映射)、夹爪命令g、执行时间戳同步。",
        "实现细节": "1) 硬件无关映射：相机与指尖相对位姿固定，无需外参；2) 关节映射：对末端ΔP执行数值/解析逆运动学得到Δq；3) 执行层：保证控制周期Δt与延迟缓冲一致，避免抖动；4) 双手部署：两策略分别映射至左右臂并保持时间同步。",
        "关键代码/公式": "逆运动学(概念表述)：给定末端相对位姿增量ΔP，计算Δq = IK(ΔP, q_t)，其中q_t为当前关节角，IK可采用数值迭代(如Levenberg-Marquardt)或解析解(视机构而定)。",
        "参数设置": "控制频率Δt与机器人控制器一致；增益与约束由机器人控制栈设定。"
      }
    },
    "4_训练与损失函数": {
      "损失函数": [
        {
          "L1": "扩散噪声预测损失",
          "公式": "L = E_{t∼[1,T], ε∼N(0,I)} [ || ε - ε_θ(x_t, t, c) ||^2 ]",
          "作用": "拟合条件分布并提升多模态动作拟合能力"
        },
        {
          "L2": "位姿平滑/可达性正则(概念)",
          "公式": "L_smooth = λ1 · Σ || Δq_{t+1} - Δq_t ||^2 + λ2 · I[不可达] + λ3 · || v_t ||^2",
          "作用": "抑制抖动、剔除不可达轨迹、限制速度"
        }
      ],
      "训练策略": "1) 构造延迟注入的观测-相对轨迹对齐数据集；2) 扩散模型训练以覆盖人类演示的多模态动作；3) 部署时固定或自适应延迟缓冲以匹配系统延迟；4) 零样本测试无需任务特定微调。",
      "优化器": "AdamW(视觉与扩散模型常见配置)；论文未给出具体β/权重衰减。",
      "学习率调度": "余弦退火/分段warmup(Diffusion Policy常用设定)；具体数值未在摘要与前18页给出。"
    },
    "5_特征设计": {
      "特征类型1": "原始鱼眼图像(单目，155° FoV；分辨率由GoPro决定，未在文中给出具体数值)",
      "特征类型2": "侧镜裁剪并数字反射(与主视角对齐；裁剪区域由镜像平面几何确定，未给出像素坐标)",
      "特征类型3": "IMU时间序列(加速度/角速度；随mp4封装与视频帧对齐)",
      "融合方式": "图像特征经卷积+时序编码得到观测嵌入z_O；相对轨迹条件c由末端增量构成；将z_O与c拼接或以交叉注意力融合后输入扩散噪声预测网络",
      "维度变化": "图像→卷积特征(未给出通道数)→时序嵌入d_model→条件向量c_cond；相对轨迹序列(Δp, ΔR, Δg)标准化/嵌入后与噪声维度对齐；最终噪声预测网络输出维度与动作序列维度匹配"
    },
    "6_实验细节": {
      "数据集": "UMI收集的人手演示视频数据(未给出规模/类别数量)，包含动态/双手/精细/长时序任务；策略在多样环境中零样本测试。",
      "评估指标": "任务成功率(SR)；分布外(Novel objects/environments)零样本成功率达70%(摘要给出)。",
      "实现环境": "手持GoPro+鱼眼+侧镜；机器人端相机与指尖相对位姿固定；ORB-SLAM3实现视觉惯性SLAM；Diffusion Policy进行策略学习；开源硬件与软件。",
      "对比方法": "与行为克隆(BC/MLP回归)、简单SfM方案、纯人类视频学习等基线比较(论文II节综述方法类别；具体实验细节与数值指标在后续页面中，摘要仅给出70%OOD成功率)。"
    },
    "7_可借鉴句子": [
      "UMI employs hand-held grippers coupled with careful interface design to enable portable, low-cost, and information-rich data collection for challenging bimanual and dynamic manipulation demonstrations.",
      "To facilitate deployable policy learning, UMI incorporates a carefully designed policy interface with inference-time latency matching and a relative-trajectory action representation.",
      "The resulting learned policies are hardware-agnostic and deployable across multiple robot platforms."
    ],
    "8_专业术语": [
      {
        "术语": "Fisheye lens",
        "中文": "鱼眼镜头",
        "解释": "超广角镜头，提供宽视场并保持中心分辨率，UMI使用155° FoV以提升视觉上下文",
        "使用场景": "手持相机采集原始鱼眼图像，策略直接使用原始图像而不进行去畸变"
      },
      {
        "术语": "Implicit stereo",
        "中文": "隐式立体",
        "解释": "通过物理侧镜在单张图像内提供多视角视图，形成虚拟双目信息用于深度线索",
        "使用场景": "侧镜裁剪经数字反射后与主视角对齐，作为策略输入提升深度与遮挡鲁棒性"
      },
      {
        "术语": "Visual-inertial SLAM",
        "中文": "视觉惯性SLAM",
        "解释": "联合优化视觉特征与IMU预积分约束的SLAM方法，用于恢复绝对尺度与鲁棒的6DoF位姿",
        "使用场景": "基于ORB-SLAM3在快速运动下维持追踪，输出端部全局位姿序列"
      },
      {
        "术语": "Relative-trajectory action representation",
        "中文": "相对轨迹动作表示",
        "解释": "以相对位姿增量(Δp, ΔR, Δg)表示动作，消除对精确绝对位姿的需求",
        "使用场景": "与延迟匹配结合，减少硬件与场景依赖，支持跨平台部署"
      },
      {
        "术语": "Inference-time latency matching",
        "中文": "推理时延匹配",
        "解释": "在训练时注入随机动作延迟，在推理时加入固定/自适应延迟缓冲，对齐感知与执行延迟",
        "使用场景": "缓解动态任务中策略输出的时间不同步问题"
      },
      {
        "术语": "Diffusion Policy",
        "中文": "扩散策略",
        "解释": "以条件扩散模型对动作序列分布进行建模，实现多模态动作的稳定生成",
        "使用场景": "作为UMI的策略学习器，条件于观测并输出相对轨迹增量序列"
      }
    ],
    "9_图表分析": [
      {
        "图表": "图2",
        "内容": "UMI演示接口硬件与相机视图：手持夹爪+GoPro、155°鱼眼、侧镜、机器人端对应配置",
        "设计亮点": "强调人/机器人观察一致性与便携性；侧镜提供隐式立体提升深度与遮挡可见性",
        "可借鉴点": "在手持数据采集中采用固定腕上相机+侧镜方案，减少外参标定与部署复杂度"
      },
      {
        "图表": "图3",
        "内容": "鱼眼图像与矫正后图像对比：矫正造成外围拉伸与中心压缩",
        "设计亮点": "说明为何使用原始鱼眼作为策略输入以保持中心信息密度",
        "可借鉴点": "在策略学习中使用原始鱼眼而非畸变矫正，避免信息丢失"
      },
      {
        "图表": "图4",
        "内容": "侧镜原理与镜像视图示例：虚拟相机反射、遮挡区域可见、数字反射统一朝向",
        "设计亮点": "隐式立体仅增加物理镜面成本，不增加传感器与重量",
        "可借鉴点": "低成本获得多视角深度线索，适用于资源受限的手持演示设备"
      }
    ],
    "10_论文总结": {
      "核心贡献": "UMI通过手持夹爪+鱼眼+侧镜+IMU-SLAM的演示接口与相对轨迹+时延匹配+Diffusion Policy的策略接口，实现了低成本、信息丰富、可跨平台部署的人手演示→机器人策略迁移；支持动态、双手、精细与长时序任务并具备零样本泛化能力。",
      "方法优势": "观察与动作本体鸿沟小(腕上相机与相对动作表示)；精度高(IMU辅助SLAM绝对尺度)；可移植性强(无外参与延迟不匹配)；泛化性好(70% OOD成功率)。",
      "局限性": "侧镜布局与裁剪参数未公开；延迟匹配的超参数(延迟区间、缓冲长度)未给出；扩散策略网络与超参数细节需参考开源；极端光照/纹理贫乏场景的SLAM鲁棒性依赖鱼眼与IMU质量。",
      "应用场景": "野外数据收集与快速任务部署；多机器人平台(6/7DoF)共享演示数据；双手协作与动态操控(投掷/接取)；长时序多阶段任务；跨环境零样本策略迁移。"
    },
    "11_阅读建议": {
      "核心学习点": "1) 观察-动作本体鸿沟的系统性最小化方法(腕上相机+相对轨迹+时延匹配)；2) 低成本硬件与高保真位姿恢复的权衡策略(鱼眼+侧镜+IMU-SLAM)。",
      "复现建议": "1) 严格保证相机-指尖相对位姿固定，减小外参依赖；2) 侧镜需做数字反射以统一方向与语义；3) 训练时务必注入随机动作延迟并做延迟缓冲；4) 动作提取中执行运动学筛选与尺度/速度阈值过滤；5) 策略建议采用相对轨迹的扩散模型，并确保采样步数与控制周期匹配。",
      "扩展方向": "1) 显式深度估计融合(如轻量立体匹配或单目深度网络)以增强遮挡鲁棒性；2) 时序建模优化(Transformer时序条件编码)以提升长时序稳定性；3) 多模态条件扩展(文本/目标语义)以增强任务可指定性；4) 端侧优化与低延迟部署(模型蒸馏、量化)以适配资源受限机器人。"
    }
  },
  "analyzed_at": "2026-01-22T00:10:16.243345"
}